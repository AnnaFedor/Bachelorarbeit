\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Problem statement}{2}{section.1.2}\protected@file@percent }
\citation{sahbani2012overview}
\citation{nguyen1988constructing}
\citation{murray2017mathematical}
\citation{shimoga1996robot}
\citation{ding2000computing}
\citation{ding2000computing}
\citation{ding2000computing}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related work}{3}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Approaches for Solving the Grasping Problem}{3}{section.2.1}\protected@file@percent }
\citation{bohg2013data}
\citation{bohg2013data}
\citation{bohg2013data}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Outtake from "Computing 3-D Optimal Form-Closure Grasps" \cite  {ding2000computing} of Ding et al. The image shows the position of the friction cone at a grasping point on the object's surface. In order for fingers not to clip while executing the grasp, the finger force must lie in the friction cone.\relax }}{4}{figure.caption.3}\protected@file@percent }
\citation{ekvall2007learning}
\citation{redmon2015real}
\citation{Cornellgraspingdataset}
\citation{mahler2017dex}
\citation{kasper2012kit}
\citation{mahler2016dex}
\citation{mahler2017dex}
\citation{pinto2016supersizing}
\citation{pinto2016supersizing}
\citation{bohg2013data}
\citation{tremblay2018deep}
\citation{lepetit2009epnp}
\citation{manuelli2019kpam}
\citation{zeng2018robotic}
\citation{bohg2011mind}
\citation{pinto2016supersizing}
\citation{zeng2019tossingbot}
\citation{zeng2018robotic}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Classification of different aspects that influence the grasping problem according to \cite  {bohg2013data} of Bohg et al. The most important aspect is the prior knowledge of the object.\relax }}{5}{figure.caption.4}\protected@file@percent }
\citation{levine2018learning}
\citation{pinto2016supersizing}
\citation{goldfeder2011data}
\citation{miller2004graspit}
\citation{kasper2012kit}
\citation{leon2010opengrasp}
\citation{james2019sim}
\citation{bousmalis2018using}
\citation{redmon2015real}
\citation{tobin2017domain}
\citation{tremblay2018deep}
\citation{patel2015visual}
\citation{bousmalis2018using}
\citation{levine2016end}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Simulation}{7}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}End-To-End Learning}{7}{section.2.3}\protected@file@percent }
\citation{saxena2008robotic}
\citation{sengupta2019going}
\citation{he2016deep}
\citation{huang2017densely}
\citation{zeng2019tossingbot}
\citation{liang2019knowledge}
\citation{zeng2018learning}
\citation{berscheid2019improving}
\citation{zeng2019tossingbot}
\citation{zeng2018learning}
\citation{bousmalis2018using}
\citation{levine2018learning}
\citation{pinto2016supersizing}
\citation{zeng2018learning}
\citation{berscheid2019improving}
\citation{kaelbling1996reinforcement}
\citation{quillen2018deep}
\citation{boularias2015learning}
\citation{von2007tutorial}
\citation{zeng2018learning}
\citation{zeng2019tossingbot}
\citation{liang2019knowledge}
\citation{liang2019knowledge}
\citation{zeng2019tossingbot}
\citation{zeng2018learning}
\citation{zeng2018learning}
\citation{zeng2019tossingbot}
\citation{liang2019knowledge}
\citation{zeng2018learning}
\citation{liang2019knowledge}
\citation{zeng2019tossingbot}
\citation{liang2019knowledge}
\citation{zeng2018learning}
\citation{zeng2019tossingbot}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Vision-based Learning}{8}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Deep reinforcement learning for grasping problems}{8}{section.2.5}\protected@file@percent }
\citation{vinyals2017starcraft}
\citation{mnih2013playing}
\citation{kormushev2013reinforcement}
\citation{zeng2018learning}
\citation{kaelbling1996reinforcement}
\citation{spinningup}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Reinforcement learning}{10}{section.2.6}\protected@file@percent }
\citation{bansal2017mbmf}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Reinforcement Learning Algorithms}{11}{section.2.7}\protected@file@percent }
\citation{haarnoja2018soft}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Soft Actor-Critic}{12}{subsection.2.7.1}\protected@file@percent }
\citation{schulman2017proximal}
\citation{schulman2015trust}
\citation{schulman2017proximal}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Description of the SAC algorithm from the original paper. First the agent collects some experience which is saved in the replay buffer D. After that all five networks are updated using information from the replay buffer.\relax }}{13}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Proximal Policy Optimization Algorithm}{13}{subsection.2.7.2}\protected@file@percent }
\citation{mao2016resource}
\citation{mao2016resource}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Approach}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The goal of the Deep Reinforcement learning approach is to develop a policy that decides which action at which step the agent should take. In order to do that the agent interacts with the environment by observing environment's state, taking actions and getting rewards for them. This way the agent determines through trial-and-error the correct behavior. Source of the image: \cite  {mao2016resource}\relax }}{16}{figure.caption.6}\protected@file@percent }
\citation{todorov2012mujoco}
\citation{pickplace2018openai}
\citation{stable-baselines}
\citation{todorov2012mujoco}
\citation{erez2015simulation}
\citation{opengl}
\citation{mujoco-documentation}
\citation{openai}
\citation{1606.01540}
\citation{baselines}
\citation{openai}
\citation{stable-baselines}
\citation{rl-zoo}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Implementation}{17}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}System components}{17}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Mujoco}{17}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}OpenAI Gym}{17}{subsection.4.1.2}\protected@file@percent }
\citation{pickplace2018openai}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Stable Baselines}{18}{subsection.4.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Custom environment example for using stable baselines. The CustomEnv inherits from gym.Env and implements methods {\_\_init\_\_()}, step(), reset(), render(), close() which is a requirement to be able to train using one of the reinforcement leaning algorithm's implementation from stable baselines.\relax }}{18}{figure.caption.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Simulation Setup}{18}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Observation Space}{19}{section.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The camera on the side of the table takes an RGB-image of the part of the table where the object can be located. The second image is an example of the observation that is used as state representation and input to the neural network\relax }}{19}{figure.caption.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Reward Function}{19}{section.4.4}\protected@file@percent }
\citation{zeng2018learning}
\citation{zeng2019tossingbot}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces In the first image the gripper's jaws are fully closed after the grasped attempt - the object was not grasped. In the second image the attempt was successful, the object is between the jaws preventing them from closing, so the distance between the jaws is slightly greater or equals the width of the object.\relax }}{20}{figure.caption.9}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Action Space}{20}{section.4.5}\protected@file@percent }
\newlabel{section:action_space}{{4.5}{20}{Action Space}{section.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Continuous Action Space}{20}{subsection.4.5.1}\protected@file@percent }
\newlabel{section:continuous_action_space}{{4.5.1}{20}{Continuous Action Space}{subsection.4.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Continuous Action Space: the action (x, y) is target cartesian coordinates of the gripper.\relax }}{20}{figure.caption.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Discrete Action Space without Rotation}{21}{subsection.4.5.2}\protected@file@percent }
\newlabel{section:multidiscrete_no_rotation}{{4.5.2}{21}{Discrete Action Space without Rotation}{subsection.4.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Discrete Action Space. The workspace is represented as 50*50 grid, the action (x, y) means going to the middle of the cell number (x, y) and completing the planar grasp.\relax }}{21}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Discrete Space with Rotation}{21}{subsection.4.5.3}\protected@file@percent }
\newlabel{section:multidiscrete_with_rotation}{{4.5.3}{21}{Discrete Space with Rotation}{subsection.4.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Discrete Action Space including rotation. The workspace is represented as 50*50 grid, the action (x, y, $\alpha $) means going to the middle of the cell number (x, y), rotating the gripper value in degrees that corresponds to $\alpha $ and completing the planar grasp.\relax }}{22}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Learning Algorithms}{22}{section.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}The Soft-Actor Critic Algorithm}{22}{subsection.4.6.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{exampletab}{{\caption@xref {exampletab}{ on input line 523}}{23}{The Soft-Actor Critic Algorithm}{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Hyperparameters for for the applied SAC algorithm.\relax }}{23}{table.caption.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Proximal Policy Optimization Algorithm}{23}{subsection.4.6.2}\protected@file@percent }
\newlabel{exampletab}{{\caption@xref {exampletab}{ on input line 548}}{23}{Proximal Policy Optimization Algorithm}{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Hyperparameters for for the applied PPO algorithm.\relax }}{23}{table.caption.14}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}CNN structure}{23}{section.4.7}\protected@file@percent }
\newlabel{exampletab}{{\caption@xref {exampletab}{ on input line 568}}{24}{CNN structure}{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Hyperparameters for for the applied PPO algorithm.\relax }}{24}{table.caption.15}\protected@file@percent }
\@setckpt{content/content}{
\setcounter{page}{25}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{3}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{NAT@ctr}{0}
\setcounter{parentequation}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{caption@flags}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{4}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{section@level}{1}
}
